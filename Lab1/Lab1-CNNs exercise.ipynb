{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {},
   "source": "# Deep Learning Applications: Laboratory #1"
  },
  {
   "cell_type": "markdown",
   "id": "17ed8906-bd19-4b4f-8b79-4feae355ffd6",
   "metadata": {},
   "source": "## Exercise 1: Warming Up"
  },
  {
   "cell_type": "markdown",
   "id": "edb2b6d1-3df0-464c-9a5f-8c611257a971",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "ab3a8282-2322-4dca-b76e-2f3863bc75fb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.045237Z",
     "start_time": "2024-04-28T11:57:20.026034Z"
    }
   },
   "source": [
    "# Start with some standard imports.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import wandb\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "33cc12cc-8422-47bf-8d8e-0950ac05ae96",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "Here is some basic dataset loading, validation splitting code to get you started working with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "id": "272a69db-0416-444a-9be4-5f055ff48bbb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.126097Z",
     "start_time": "2024-04-28T11:57:20.073420Z"
    }
   },
   "source": [
    "# Standard MNIST transform.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST train and test.\n",
    "ds_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "ds_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split train into train and validation.\n",
    "val_size = 5000\n",
    "I = np.random.permutation(len(ds_train))\n",
    "ds_val = Subset(ds_train, I[:val_size])\n",
    "ds_train = Subset(ds_train, I[val_size:])"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "24e05e96-7707-4490-98b8-50cb5e330af1",
   "metadata": {},
   "source": [
    "#### Boilerplate training and evaluation code\n",
    "\n",
    "This is some **very** rough training, evaluation, and plotting code. Again, just to get you started. I will be *very* disappointed if any of this code makes it into your final submission."
   ]
  },
  {
   "cell_type": "code",
   "id": "7005d3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.136293Z",
     "start_time": "2024-04-28T11:57:20.126097Z"
    }
   },
   "source": [
    "# REWRITE TRAINING AND EVALUATION FUNCTIONS \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Function to train a model for a single epoch over the data loader.\n",
    "def train_epoch(model, dl, opt, epoch='Unknown', device='cpu'):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for (xs, ys) in tqdm(dl, desc=f'Training epoch {epoch}', leave=True):\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        # Zero out the gradients.\n",
    "        opt.zero_grad()\n",
    "        # Forward through the model.\n",
    "        logits = model(xs) \n",
    "        # Compute the cross-entropy loss.\n",
    "        loss = F.cross_entropy(logits, ys)\n",
    "        # Backward through the model.\n",
    "        loss.backward()\n",
    "        # Update the model parameters.\n",
    "        opt.step()\n",
    "        # Save the loss value.\n",
    "        losses.append(loss.item())\n",
    "    # Return the average loss for this epoch.\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Function to evaluate model over all samples in the data loader.\n",
    "def evaluate_model(model, dl, device='cpu'):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    with torch.no_grad():\n",
    "        for (xs, ys) in tqdm(dl, desc='Evaluating', leave=False):\n",
    "            xs = xs.to(device)\n",
    "            logits = model(xs)\n",
    "            preds = torch.argmax(logits, 1)\n",
    "            \n",
    "            # Save the ground truth and predictions.\n",
    "            ground_truths.append(ys)\n",
    "            predictions.append(preds.detach().cpu().numpy())\n",
    "            \n",
    "    predictions = np.hstack(predictions)\n",
    "    ground_truths = np.hstack(ground_truths)\n",
    "    \n",
    "    # Return accuracy score and classification report.\n",
    "    return accuracy_score(ground_truths, predictions), classification_report(ground_truths, predictions, zero_division=0, digits=3)\n",
    "\n",
    "# Simple function to plot the loss curve and validation accuracy.\n",
    "def plot_validation_curves(training_history):\n",
    "    losses, accuracies = zip(*training_history)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses)\n",
    "    plt.title('Average Training Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(accuracies)\n",
    "    plt.title(f'Best Accuracy = {np.max(accuracies)} @ epoch {np.argmax(accuracies)}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.143467Z",
     "start_time": "2024-04-28T11:57:20.136293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, dl_train, dl_val, opt, epochs, model_name, dataset_type, device='cpu'):\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"DLA Assigment 1\",\n",
    "        name=\"MLP\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"architecture\": model_name,\n",
    "            \"dataset\": dataset_type,\n",
    "            \"epochs\": epochs,\n",
    "            \"learning_rate\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"device\": device,\n",
    "            \"optimizer\": \"Adam\"\n",
    "        }\n",
    "    )\n",
    "    losses_and_accs = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(model, dl_train, opt, epoch, device=device)\n",
    "        (val_acc, _) = evaluate_model(model, dl_val, device=device)\n",
    "        losses_and_accs.append((loss, val_acc))\n",
    "        \n",
    "        print(f'Epoch {epoch}: Loss - {loss:.4f}, Validation Acc - {val_acc:.4f}')\n",
    "        # wandb\n",
    "        wandb.log({\"acc\": val_acc, \"loss\": loss})\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f\"model_MLP_{epoch}.pt\")\n",
    "        wandb.save(f\"model_MLP_{epoch}.pt\")\n",
    "        \n",
    "    # [optional] finish the wandb run, necessary in notebooks\n",
    "    wandb.finish()    \n",
    "    \n",
    "    return losses_and_accs"
   ],
   "id": "ed84b1167357748c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "875008c3-306c-4e39-a845-d7bda7862621",
   "metadata": {},
   "source": [
    "#### A basic, parameterized MLP\n",
    "\n",
    "This is a very basic implementation of a Multilayer Perceptron. Don't waste too much time trying to figure out how it works -- the important detail is that it allows you to pass in a list of input, hidden layer, and output *widths*. **Your** implementation should also support this for the exercises to come."
   ]
  },
  {
   "cell_type": "code",
   "id": "8c1e503a-37df-4fb9-94e7-85d0adb494bd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.153290Z",
     "start_time": "2024-04-28T11:57:20.143467Z"
    }
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(nin, nout) for (nin, nout) in zip(layer_sizes[:-1], layer_sizes[1:])])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda f, g: lambda x: g(F.relu(f(x))), self.layers, lambda x: x.flatten(1))(x)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:57:20.161807Z",
     "start_time": "2024-04-28T11:57:20.153290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A non-parametric CNN.\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, num=1, channels=8, size=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Conv2d(channels, channels, kernel_size=size, padding='same') for _ in range(num)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return reduce(lambda f, g: lambda x: g(F.relu(f(x))), self.layers, lambda x: x)(x)\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num=2, channels=8, size=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, channels, kernel_size=size)\n",
    "        self.cblock1 = ConvBlock(num=num, channels=channels, size=size)\n",
    "        self.cblock2 = ConvBlock(num=num, channels=channels, size=size)\n",
    "        self.cblock3 = ConvBlock(num=num, channels=channels, size=size)\n",
    "        self.output = nn.Linear(channels, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.cblock1(x)\n",
    "        x = F.max_pool2d(x, 3, 2)\n",
    "        x = self.cblock2(x)\n",
    "        x = F.max_pool2d(x, 3, 2)\n",
    "        x = self.cblock3(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=x.shape[2:]).squeeze()\n",
    "        return self.output(x)"
   ],
   "id": "b176aa53f0d61d6f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "4ae06e26-8fa3-414e-a502-8d1c18ba9eb7",
   "metadata": {},
   "source": [
    "#### A *very* minimal training pipeline.\n",
    "\n",
    "Here is some basic training and evaluation code to get you started.\n",
    "\n",
    "**Important**: I cannot stress enough that this is a **terrible** example of how to implement a training pipeline. You can do better!"
   ]
  },
  {
   "cell_type": "code",
   "id": "91afcace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:58:01.850495Z",
     "start_time": "2024-04-28T11:57:59.500597Z"
    }
   },
   "source": [
    "# Training hyperparameters.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "epochs = 50\n",
    "lr = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture hyperparameters.\n",
    "input_size = 28*28\n",
    "width = 16\n",
    "depth = 2\n",
    "\n",
    "# Dataloaders.\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=True, num_workers=4)\n",
    "dl_val   = torch.utils.data.DataLoader(ds_val, batch_size, num_workers=4)\n",
    "dl_test  = torch.utils.data.DataLoader(ds_test, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Instantiate model and optimizer.\n",
    "model_mlp = MLP([input_size] + [width]*depth + [10]).to(device)\n",
    "opt = torch.optim.Adam(params=model_mlp.parameters(), lr=lr)\n",
    "\n",
    "# Training \n",
    "losses_and_accs = train_model(model_mlp, dl_train, dl_val, opt, epochs, device=device)\n",
    "\n",
    "# And finally plot the curves.\n",
    "plot_validation_curves(losses_and_accs)\n",
    "print(f'Accuracy report on TEST:\\n {evaluate_model(model_mlp, dl_test, device=device)[1]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_model() missing 2 required positional arguments: 'model_name' and 'dataset_type'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m opt \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params\u001B[38;5;241m=\u001B[39mmodel_mlp\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Training \u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m losses_and_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_mlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# And finally plot the curves.\u001B[39;00m\n\u001B[0;32m     26\u001B[0m plot_validation_curves(losses_and_accs)\n",
      "\u001B[1;31mTypeError\u001B[0m: train_model() missing 2 required positional arguments: 'model_name' and 'dataset_type'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "de2cad13-ee2c-4e43-b5c7-31760da8c2df",
   "metadata": {},
   "source": "### Exercise 1.1: A baseline MLP"
  },
  {
   "cell_type": "code",
   "id": "19d96405-36e7-4074-803c-fb02576cd528",
   "metadata": {
    "tags": []
   },
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(28*28, 128),  # First narrow layer\n",
    "            nn.Linear(128, 128),  # Second narrow layer\n",
    "            nn.Linear(128, 64),  # Third narrow layer\n",
    "            nn.Linear(64, 64), # Fourth narrow layer\n",
    "            nn.Linear(64, 10)  # Output layer\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d2869de",
   "metadata": {},
   "source": [
    "# Training hyperparameters.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device {device}')\n",
    "epochs = 100\n",
    "lr = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DLA Assigment 1\",\n",
    "    name=\"SimpleMLP\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"architecture\": \"MLP\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Dataloaders.\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=True, num_workers=4)\n",
    "dl_val   = torch.utils.data.DataLoader(ds_val, batch_size, num_workers=4)\n",
    "dl_test  = torch.utils.data.DataLoader(ds_test, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Instantiate model and optimizer.\n",
    "model_mlp = SimpleMLP().to(device)\n",
    "print(model_mlp.layers)\n",
    "opt = torch.optim.Adam(params=model_mlp.parameters(), lr=lr)\n",
    "\n",
    "# Training\n",
    "losses_and_accs = train_model(model_mlp, dl_train, dl_val, opt, epochs, device=device)\n",
    "\n",
    "# And finally plot the curves.\n",
    "plot_validation_curves(losses_and_accs)\n",
    "print(f'Accuracy report on TEST:\\n {evaluate_model(model_mlp, dl_test, device=device)[1]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0fb8ad9b-e3ae-4c49-9bec-35aaea149b08",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Rinse and Repeat\n",
    "\n",
    "Repeat the verification you did above, but with **Convolutional** Neural Networks. If you were careful about abstracting your model and training code, this should be a simple exercise. Show that **deeper** CNNs *without* residual connections do not always work better and **even deeper** ones *with* residual connections.\n",
    "\n",
    "**Hint**: You probably should do this exercise using CIFAR10, since MNIST is *very* easy (at least up to about 99% accuracy).\n",
    "\n",
    "**Spoiler**: If you plan to do optional exercise 2.3, you should think *very* carefully about the architectures of your CNNs here (so you can reuse them!)."
   ]
  },
  {
   "cell_type": "code",
   "id": "3c8baa0e-b17f-4a77-8a88-dadfdc6763ea",
   "metadata": {},
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4646fd27",
   "metadata": {},
   "source": [
    "import torchvision\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DLA Assigment 1\",\n",
    "    name=\"SimpleCNN\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"MLP\",\n",
    "    \"dataset\": \"CIFAR\",\n",
    "    \"epochs\": 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dl_train = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "dl_val = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop.\n",
    "losses_and_accs = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train_epoch(model_mlp, dl_train, opt, epoch, device=device)\n",
    "    (val_acc, _) = evaluate_model(model_mlp, dl_val, device=device)\n",
    "    losses_and_accs.append((loss, val_acc))\n",
    "    \n",
    "    # wandb\n",
    "    wandb.log({\"acc\": val_acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "\n",
    "# And finally plot the curves.\n",
    "plot_validation_curves(losses_and_accs)\n",
    "print(f'Accuracy report on TEST:\\n {evaluate_model(model_mlp, dl_test, device=device)[1]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef4de2f2-abc5-4f98-9eaf-3497f734a022",
   "metadata": {},
   "source": [
    "-----\n",
    "## Exercise 2: Choose at Least One\n",
    "\n",
    "Below are **three** exercises that ask you to deepen your understanding of Deep Networks for visual recognition. You must choose **at least one** of the below for your final submission -- feel free to do **more**, but at least **ONE** you must submit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978e8e-9f2e-4949-9699-495af6cb6349",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Explain why Residual Connections are so effective\n",
    "Use your two models (with and without residual connections) you developed above to study and **quantify** why the residual versions of the networks learn more effectively.\n",
    "\n",
    "**Hint**: A good starting point might be looking at the gradient magnitudes passing through the networks during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "id": "469e81a3-08ca-4549-a2f8-f47cf5a0308b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Your code here."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "440a3a7b-2ed6-4f58-a1b7-5ab1fc432893",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Fully-convolutionalize a network.\n",
    "Take one of your trained classifiers and **fully-convolutionalize** it. That is, turn it into a network that can predict classification outputs at *all* pixels in an input image. Can you turn this into a **detector** of handwritten digits? Give it a try.\n",
    "\n",
    "**Hint 1**: Sometimes the process of fully-convolutionalization is called \"network surgery\".\n",
    "\n",
    "**Hint 2**: To test your fully-convolutionalized networks you might want to write some functions to take random MNIST samples and embed them into a larger image (i.e. in a regular grid or at random positions)."
   ]
  },
  {
   "cell_type": "code",
   "id": "9e33c912-0716-44ef-a91b-47ca19a2b2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Your code here."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8243f811-8227-4c6f-b07f-56e8cd91643a",
   "metadata": {},
   "source": [
    "### Exercise 2.3: *Explain* the predictions of a CNN\n",
    "\n",
    "Use the CNN model you trained in Exercise 1.2 and implement [*Class Activation Maps*](http://cnnlocalization.csail.mit.edu/#:~:text=A%20class%20activation%20map%20for,decision%20made%20by%20the%20CNN.):\n",
    "\n",
    "> B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. CVPR'16 (arXiv:1512.04150, 2015).\n",
    "\n",
    "Use your implementation to demonstrate how your trained CNN *attends* to specific image features to recognize *specific* classes.\n",
    "\n",
    "**Note**: Feel free to implement [Grad-CAM](https://arxiv.org/abs/1610.02391) instead of CAM."
   ]
  },
  {
   "cell_type": "code",
   "id": "d634a700-56c2-48fd-96e0-4c94d1bd0cfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Your code here."
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
