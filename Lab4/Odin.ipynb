{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import FakeData\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "fakeset = FakeData(size=1000, image_size=(3, 32, 32), transform=transform)\n",
    "fakeloader = torch.utils.data.DataLoader(fakeset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple CNN model.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CELL TO LOAD THE PRETRAINED MODEL.\n",
    "device = 'cpu'\n",
    "loss = nn.CrossEntropyLoss()\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load('./OOD_CNN.pth',map_location=torch.device('cpu'))) #50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_softmax(logit, T=1.0, delta= 0.5):\n",
    "    s = F.softmax(logit/T, 1)\n",
    "    s = s.max(dim=1)[0] #get the max for each element of the batch\n",
    "    return s\n",
    "    \n",
    "\n",
    "\n",
    "def compute_scores(data_loader, score_fun):\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            x, y = data\n",
    "            output = model(x.to(device))\n",
    "            s = score_fun(output)\n",
    "            scores.append(s)\n",
    "        scores_t = torch.cat(scores)\n",
    "        return scores_t\n",
    "\n",
    "\n",
    "def OOD_det(model, data_loader, T, eps, delta):\n",
    "    score = []\n",
    "    for data in data_loader:\n",
    "        model.train()\n",
    "        x,y = data\n",
    "        \n",
    "        x.requires_grad=True \n",
    "\n",
    "        x.retain_grad()\n",
    "\n",
    "        output=model(x)\n",
    "        model.zero_grad()\n",
    "        l = loss(output,y)\n",
    "        l.backward()\n",
    "        v = x + eps*torch.sign(x.grad)#fgsm\n",
    "        with torch.no_grad():\n",
    "            logit = model(v)\n",
    "            s = max_softmax(logit, T, delta)\n",
    "            for i in range(np.shape(s)[0]): #calcolo della funzione g\n",
    "                if s[i]>delta:\n",
    "                    score.append(1)\n",
    "                else:\n",
    "                    score.append(0)\n",
    "    score_t = torch.tensor(score)\n",
    "    return score_t\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GRID SEARCH ON EPS, T, DELTA(?). Uso test set come validation set.\n",
    "\n",
    "\n",
    "e = np.linspace(0, 0.004, 10)#10 valori da 0 a 0.004 come nel paper su ODIN\n",
    "t = np.array([1, 5, 10, 50, 100, 500, 1000])\n",
    "\n",
    "for eps in e:\n",
    "    for temp in t:\n",
    "        scores_fake= OOD_det(model, fakeloader, temp, eps, delta=0.5)\n",
    "        scores_test= OOD_det(model, testloader, temp, eps, delta=0.5)\n",
    "        y_test = torch.ones_like(scores_test)\n",
    "        y_fake = torch.zeros_like(scores_fake)\n",
    "        y = torch.cat((y_test, y_fake))\n",
    "        y_pred = torch.cat((scores_test, scores_fake))\n",
    "        s = metrics.roc_auc_score(y, y_pred)\n",
    "        print(\"AUC for eps = %s, temp = %s is %s\" % (eps, temp, s))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
